{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4cb5dd1",
   "metadata": {},
   "source": [
    "## 4. Concatenate & Split Dataset\n",
    "Now that we have a large number of tweet sequences for Russian and Chinese state operators as well as typical Twitter users, we'll combine the sequences and create a random test-train split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4602edb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33b331a",
   "metadata": {},
   "source": [
    "### 4.1 Load and Join Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffc2766",
   "metadata": {},
   "outputs": [],
   "source": [
    "russian = pd.read_csv(\"../working_files/russian_tweet_sequences.csv\", lineterminator='\\n',index_col=0)\n",
    "russian['operator'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024bd401",
   "metadata": {},
   "outputs": [],
   "source": [
    "russian.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c5e6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "chinese = pd.read_csv(\"../working_files/chinese_tweet_sequences.csv\", lineterminator='\\n',index_col=0)\n",
    "chinese['operator'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6841dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "chinese.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e27919b",
   "metadata": {},
   "outputs": [],
   "source": [
    "real = pd.read_csv(\"../working_files/real_tweet_sequences.csv\", lineterminator='\\n',index_col=0)\n",
    "real['operator'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e29eab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "real.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2636cecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs = pd.concat([russian, chinese, real])\n",
    "final_cols = ['userid','tweet_text','tweet_time','clean_tweets','recent_tweets','operator']\n",
    "\n",
    "seqs = seqs[final_cols].copy()\n",
    "seqs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ccb351",
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs['seq_id'] = range(0, len(seqs))\n",
    "seqs.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6427c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs[\"operator\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18005ff8",
   "metadata": {},
   "source": [
    "### 4.2 Split Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05aeb4c",
   "metadata": {},
   "source": [
    "### 4.2.1 Test Set\n",
    "Here, we'll split off 10% of the data to use after we have tuned hyperparameters and fine-tuned the model. We keep this aside to ensure we aren't overfitting through hyperparameter selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fafe12",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = seqs.sample(n=int(0.1*len(seqs)), random_state=13, replace=False)\n",
    "test_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733e5c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set.to_csv('../data/test.csv',index=False, sep=',', quotechar='\"',header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a75fae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids = test_set['seq_id'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e62882",
   "metadata": {},
   "source": [
    "### 4.2.2 Training Set\n",
    "This dataset will be used for training, and we'll randomly split it into validation and training sets in the next notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3131eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = seqs[~seqs['seq_id'].isin(test_ids)]\n",
    "training_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435cb7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set.to_csv('../data/train.csv',index=False, sep=',', quotechar='\"',header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf2eb0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "715799c5962b37cda2a43057b7b6f81562e2f9a9ac0bada816b8b08e4df60984"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 ('pytorch-dl-hf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
